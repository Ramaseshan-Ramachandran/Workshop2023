{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "RNN for Language Model"
      ],
      "metadata": {
        "id": "PGnKiKXZqcGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJc114rsDkvo",
        "outputId": "a57e1b3a-57ad-4141-f59b-3f923db1cbc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import save_model, load_model\n",
        "import re\n",
        "\n",
        "# Step 1: Prepare the Dataset\n",
        "corpus_folder = '/content/drive/MyDrive/Datasets/Budget_speech/TXT'\n",
        "\n",
        "def read_corpus(corpus_folder='/content/drive/MyDrive/Datasets/Budget_speech/TXT'):\n",
        "    corpus_text = ''\n",
        "    for filename in os.listdir(corpus_folder):\n",
        "        file_path = os.path.join(corpus_folder, filename)\n",
        "        with open(file_path, \"r\") as f:\n",
        "            corpus_text += f.read().lower()\n",
        "    return corpus_text\n",
        "\n",
        "# Step 2: Text Preprocessing\n",
        "\n",
        "def process_text():\n",
        "    corpus_text = read_corpus()\n",
        "    filters = '!\"#$%&()*+/:;<=>?@[\\\\]^_`{|}~'\n",
        "    tokenizer = Tokenizer(filters=filters)\n",
        "    tokenizer.fit_on_texts([corpus_text])\n",
        "\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    sequences = tokenizer.texts_to_sequences([corpus_text])[0]\n",
        "    return vocab_size, sequences, tokenizer\n",
        "\n",
        "# Step 3: Prepare Training Data\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    vocab_size, sequences,tokenizer = process_text()\n",
        "    sequence_length = 10\n",
        "    sequences = np.array(sequences)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(sequence_length, len(sequences)):\n",
        "        sequence = sequences[i-sequence_length:i]\n",
        "        target = sequences[i]\n",
        "        X.append(sequence)\n",
        "        y.append(target)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Pad sequences if needed\n",
        "    X = pad_sequences(X, maxlen=sequence_length)\n",
        "\n",
        "    # Step 4: Build the Language Model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 100, input_length=sequence_length))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "    return X,y, model\n",
        "\n",
        "def train():\n",
        "\n",
        "    X,y,model = build_model()\n",
        "    #we can add {epoch:02d}-{loss:.4f} to the filename to create epoch-wise chp files\n",
        "    check_point_file = '/content/drive/MyDrive/Datasets/Budget_speech/Models/model_checkpoint.30+{epoch:02d}-{loss:.4f}.h5'\n",
        "    if os.path.isfile('/content/drive/MyDrive/Datasets/Budget_speech/Models/model_checkpoint.10+20-1.3278.h5'):\n",
        "      model.load_weights('/content/drive/MyDrive/Datasets/Budget_speech/Models/model_checkpoint.10+20-1.3278.h5')\n",
        "    # Step 5: Train the Language Model\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(check_point_file,\n",
        "                                        save_weights_only=False,\n",
        "                                        save_best_only=True,\n",
        "                                        monitor='val_loss')\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # checkpoint_callback = ModelCheckpoint('./Models/model_checkpoint.h5',\n",
        "    #                                       save_weights_only=False, save_best_only=True)\n",
        "    # model.fit(X, y, batch_size=128, epochs=2, callbacks=[checkpoint_callback])\n",
        "    model.fit(X, y, batch_size=128, epochs=10,\n",
        "            validation_data=(X, y),\n",
        "            callbacks=[checkpoint_callback])\n",
        "\n",
        "    # model.save('/content/drive/MyDrive/Datasets/Budget_speech/Models/Keras_RNN.LM')\n",
        "\n",
        "def generate_sentences(seed_text, num_sentences, sequence_length):\n",
        "    _,_,tokenizer = process_text()\n",
        "    _,_,model = build_model()\n",
        "    check_point_file = '/content/drive/MyDrive/Datasets/Budget_speech/Models/model_checkpoint.h5'\n",
        "    if os.path.isfile('/content/drive/MyDrive/Datasets/Budget_speech/Models/model_checkpoint.10+20-1.3278.h5'):\n",
        "      model.load_weights(check_point_file)\n",
        "\n",
        "\n",
        "    generated_text = seed_text + ': '\n",
        "    for _ in range(num_sentences):\n",
        "        for _ in range(sequence_length):\n",
        "            input_sequence = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "            input_sequence = np.array(input_sequence)\n",
        "            input_sequence = pad_sequences([input_sequence], maxlen=sequence_length)\n",
        "\n",
        "            predicted_index = np.argmax(model.predict(input_sequence))\n",
        "            predicted_word = tokenizer.index_word[predicted_index]\n",
        "\n",
        "            seed_text += \" \" + predicted_word\n",
        "\n",
        "            if predicted_word == '.':\n",
        "                break\n",
        "\n",
        "        generated_text += seed_text\n",
        "        seed_text = predicted_word\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "train()\n",
        "\n",
        "seed_text = \"budget speech\"\n",
        "num_sentences = 5\n",
        "generated_text_length = 100\n",
        "sequence_length = 10\n",
        "\n",
        "# model = load_model('/content/drive/MyDrive/Datasets/Budget_speech/Models/Keras_RNN.LM')\n",
        "generated_text = generate_sentences(seed_text, num_sentences, sequence_length)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bSK0D6JdRMF",
        "outputId": "cb087474-0d60-4c83-d896-4030d8312c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 100)           8927100   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 128)           117248    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 89271)             11515959  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,691,891\n",
            "Trainable params: 20,691,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1490/7079 [=====>........................] - ETA: 2:45 - loss: 1.1826"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After 1 iteration**\n",
        "\n",
        "budget speech: budget speech the government is proposed to provide that the government isis being made to the extent of the states and thethe manufacture of duty on the income tax act is beingbeing reduced from 10 to 20 per cent to 10 perper cent to 10 per cent to 10 per cent to"
      ],
      "metadata": {
        "id": "AxTRxc99mqCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After 10 iterations**\n",
        "\n",
        "budget speech: budget speech with india’s respective things, provide substantial\n",
        "employment. a new rural developmentdevelopment of andhra pradesh and other\n",
        "disadvantaged women shgs have been completedcompleted recovery of jammu kashmir farmers have been completed. the\n",
        "flagship newnew ‘updated city city blocks and assam and tamil nadu, uttaruttar pradesh, jammu petrochemicals, gas technology development of\n",
        "cctv and is notified"
      ],
      "metadata": {
        "id": "32RwoJnfAo_Y"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}